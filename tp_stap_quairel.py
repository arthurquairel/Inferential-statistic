# -*- coding: utf-8 -*-
"""TP-STAP_Quairel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tMd8s5lPP3lkRXlHAhlYJYa_TUA0gtmD
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.io import loadmat
import scipy.linalg as linalg
import scipy.stats as st
from scipy.stats import ttest_ind
from scipy.stats import chi2_contingency

"""# Introduction

Les tests statistiques constituent des outils essentiels pour l‚Äôanalyse de donn√©es dans de nombreux contextes du quotidien. Qu‚Äôil s‚Äôagisse, comme dans ce travail pratique, de l‚Äô√©tude des tailles d‚Äôindividus, ou de probl√©matiques plus sensibles telles que l‚Äô√©valuation du risque d‚Äôerreur dans un diagnostic m√©dical, les tests statistiques, associ√©s aux intervalles de confiance, permettent d‚Äô√©clairer la prise de d√©cision des sp√©cialistes s'ils sont bien mit en place.

Dans ce TP, nous commencerons par explorer une exp√©rience illustrant le th√©or√®me de la limite centrale. Nous poursuivrons avec une √©tude des intervalles de confiance, avant d‚Äôanalyser une distribution de tailles humaines afin d‚Äôappliquer et de mieux comprendre diff√©rents tests statistiques.

Ce compte rendu est r√©alis√© par Raphael T√∂rnqvist et Arthur Quairel, √©l√®ves du groupe 1 .

# Exercice √† partir de donn√©es synth√©tiques

Dans cet exercice, nous allons nous m√™me engendrer les donn√©es afin d'exp√©rimenter le theor√®me de la limite centrale (ou TCL).

Le th√©or√®me de la limite centrale, de fa√ßon informelle, donne une estimation pr√©cise de l'erreur que l'on commet en approchant l'esp√©rance math√©matique par la moyenne arithm√©tique (historiquement nomm√© th√©or√®me des erreurs par Gauss).

Soit $X_n$ une suite de v.a. de m√™me loi d'esp√©rance $\mu$ et d'√©cart type $\sigma$. Alors la v.a.
$$ Z_n = \frac{(X_1 + \cdots + X_n) -n\mu}{\sigma\sqrt{n}} \longrightarrow \mathcal{N}(0,1)$$

dit autrement:

$$ \frac{(X_1 + \cdots + X_n)}{n} \longrightarrow \mathcal{N}(\mu,\frac{\sigma}{\sqrt{n}})$$

et aussi:
$$ (X_1 + \cdots + X_n) \longrightarrow \mathcal{N}(n\mu,\sigma*\sqrt{n})$$

Prenons $n$ √©chantillons au hasard dans une population telle que la caract√©ristique observ√©e est norm√©e centr√©e.
"""

n=10
samples = np.random.randn(n)
#samples = np.random.randn(n)*ecart*np.sqrt(n)+ n*moyenne
samples.mean()

"""La moyenne n'est pas proche de 0 ! Ainsi en observant que ces $n$ valeurs, notre estimation de la moyenne n'est pas tr√®s bonne. Mais c'est peut √™tre qu'on a pas eu de chance.  Alors recommen√ßons ! Dans ce cas l'estimateur de la moyenne d'apr√®s un √©chantillonage de $n$ valeur devient lui m√™me une variable al√©atoire."""

M1 = 100 #¬†Pour M = 100
L1=[]
for i in range(M1):
  L1.append(np.random.randn(n).mean()) #Cr√©ation de la liste contenant les M1 valeurs moyennes des echantillons de 10 variables

plt.figure(figsize=(15, 5))

plt.subplot(1,3,1) #¬†Trac√© de l'histogramme des estimations pour M = 100
plt.hist(L1, bins=30, density=True, color='lightgreen',edgecolor='black')
plt.title(f'M = {M1} estimations')



M2 = 1000 #¬†Pour M = 1000
L2=[]
for i in range(M2):
  L2.append(np.random.randn(n).mean()) #Cr√©ation d'une liste avec plus de valeurs moyennes car M2>M1

plt.subplot(1,3,2) #¬†Trac√© de l'histogramme des estimations pour M = 1000
plt.hist(L2, bins=50, density=True, color='lightgreen',edgecolor='black')
plt.title(f'M = {M2} estimations')


M3 = 10000 #¬†Pour M = 10000
L3=[]
for i in range(M3):
  L3.append(np.random.randn(n).mean())

plt.subplot(1,3,3) #¬†Trac√© de l'histogramme des estimations pour M = 10000
plt.hist(L3, bins=100, density=True, color='lightgreen',edgecolor='black')
plt.title(f'M = {M3} estimations')


plt.tight_layout()
plt.show()

"""On remarque que plus on fait d'estimations plus la r√©partitions de nos moyennes  tend vers une gaussienne centr√©e r√©duite. Ce r√©sultat est d'autant plus vrai que la valeur de M est importante. Pour M = 100, on remarque une tendance de gausienne, alors que pour M = 10000 il est clair que la l'histogramme est une gausienne. Cette simulation permet de confirmer le th√©or√®me central limite.

L'estimation est une somme de $n=10$ variables al√©atoires , chacune normale et normalis√©e sur $n$. Une somme de gaussienne avec m√™me variance, reste une gaussienne.

On voit que sur 100 √©chantillonnages diff√©rents (chacun prenant 10 valeurs),  l'estimation de la moyenne est tr√®s incertaine. Si on augmente $n$ est-ce  que serait mieux ?
"""

#¬†Tracer l'histogramme des estimations pour chaque n.

M=100 #¬†cette fois  M est fix√© √† 100
n1=10 #¬†et n varie : 10, 100, 1000, 10000
n2=100
n3=1000
n4=10000


plt.figure(figsize=(20, 5))


L1=[]
for i in range(M):
  L1.append(np.random.randn(n1).mean()) #Cr√©ation de la liste comprennant les M valeurs moyennes des √©chantillons de tailles n1

plt.subplot(1,4,1) #¬†Trac√© de l'histogramme des estimations pour n = 10
plt.hist(L1, bins=30, density=True, color='salmon',edgecolor='black')
plt.title(f'n = {n1} variables al√©atoires')


L2=[]
for i in range(M):
  L2.append(np.random.randn(n2).mean()) #Cr√©ation de la liste comprenant les M valeurs moyennes des √©chantillons de tailles n2

plt.subplot(1,4,2) #¬†Trac√© de l'histogramme des estimations pour n = 100
plt.hist(L2, bins=30, density=True, color='salmon',edgecolor='black')
plt.title(f'n = {n2} variables al√©atoires')



L3=[]
for i in range(M):
  L3.append(np.random.randn(n3).mean())

plt.subplot(1,4,3) #¬†Trac√© de l'histogramme des estimations pour n = 1000
plt.hist(L3, bins=30, density=True, color='salmon',edgecolor='black')
plt.title(f'n = {n3} variables al√©atoires')


L4=[]
for i in range(M):
  L4.append(np.random.randn(n4).mean())

plt.subplot(1,4,4) #¬†Trac√© de l'histogramme des estimations pour n = 10000
plt.hist(L4, bins=30, density=True, color='salmon',edgecolor='black')
plt.title(f'n = {n4} variables al√©atoires')

"""On voit que la variance de l'estimateur diminue avec $n$, mais on voit aussi qu'augmenter la taille de l'√©chantillon ne modifie pas drastiquement l'histogramme.



Toute la question est alors: √† partir de mon √©chantillon, mon estimation de la moyenne est-elle fiable ou pas. On peut alors choisir non pas d'estimer cette moyenne mais de d√©terminer un intervalle de confiance.  

## Intervalle de confiance

De mani√®re g√©n√©rale, le param√®tre √† estimer √† partir d'un √©chantillon est $\theta$:
- Soit $\alpha \in ]0, 1[$ le niveau de risque.
- S‚Äôil existe des v.a.r $\theta_{min}(X1, . . . , Xn)$ et $\theta_{max}(X1, . . . , Xn)$
 telles que
 $$ P(\theta \in [\theta_{min}, \theta_{max}]) = 1 ‚àí \alpha$$

On dit alors que $[\theta_{min}, \theta_{max}]$ est un intervalle de
confiance pour $\theta$, avec coefficient de s√©curit√© $1 ‚àí \alpha$. On le note $IC_{1‚àí\alpha}(\theta)$. Dit autrement, si on effectue plein d'√©chantillonnage, la probabilit√© d'observer la valeur $\theta$ dans l'IC est de $1-\alpha$.


## Pour la moyenne
Si on souhaite estimer la moyenne empirique √† partir de $n$ √©chantillons, partons
du TCL,
$$ \bar{X_n} = \frac{(X_1 + \cdots + X_n)}{n} $$

$$ Z_n = \sqrt{n}\big(\frac{ \bar{X_n}-  \mu}{\sigma} \big) \longrightarrow \mathcal{N}(0,1)$$

On cherche $\theta_{min}$ et $\theta_{max}$ tq
$$ P( \theta_{min}  < Z_n < \theta_{max} ) = 1 -\alpha$$

- $Z_n$ tend vers une loi normale, centr√©e r√©duite donc
$\theta_{min} = - \theta_{max} = -z_{1-\alpha/2}$.
- La probabilit√© $\alpha$ se r√©partit en 2 parties √©gales √† $\alpha/2$


"""

x = np.linspace(-5,5,1000)
y = st.norm.pdf(x) # par defaut N(0,1)
plt.grid()
plt.plot(x,y)
plt.title('La loi normale centr√©e r√©duite')

for alpha in [0.01, 0.05, 0.1]: #Mise en place de la liste d'alpha que nous allons tester
    xcritic = abs(st.norm.ppf(alpha/2)) #Calcul de la valeur critique pour l'intervalle de confiance
    print(f"Pour Œ± = {alpha}: Valeur critique (absolue) = {xcritic:.4f}")

"""Ici nous avons montr√© qu'en fonction des valeurs de Œ± que l'on choisit, la valeur critiqeu de d√©but et de fin de l'intervalle de confiance varie assez cons√©quement, on pouvait s'y attendre sachant qu'on passe d'un intervalle de confiance de 99 % √† un intervalle de 90%.  """

alpha = 0.05 # Intervalle de confiance √† 95 %
xcritic=st.norm.ppf(alpha/2)
#plt.plot(x,y)
sel = x < xcritic
#plt.fill_between(x[sel],y[sel], 0, color='red', edgecolor='black',alpha=1)
sel = x >  - xcritic
#_ = plt.fill_between(x[sel],y[sel], 0, color='red', edgecolor='black',alpha=1)
#plt.grid()
#plt.title('Intervalle de confiance √† 95% ')




xcritic_left = st.norm.ppf(alpha/2)   # Borne inf√©rieure
xcritic_right = -xcritic_left          # Borne sup√©rieure


plt.figure(figsize=(10, 6))
plt.plot(x, y, 'b-', linewidth=2, label='Distribution normale standard')

#On remplit et les zones de rejet et l'intervalle de confance
plt.fill_between(x[x < xcritic_left], y[x < xcritic_left], 0,
                color='red', alpha=0.5, label=f'Zone de rejet (Œ±/2 = {alpha/2:.3f})')
plt.fill_between(x[x > xcritic_right], y[x > xcritic_right], 0,
                color='red', alpha=0.5)

plt.fill_between(x[(x >= xcritic_left) & (x <= xcritic_right)],
                 y[(x >= xcritic_left) & (x <= xcritic_right)], 0,
                 color='green', alpha=0.3,
                 label=f'Intervalle de confiance (1-Œ± = {(1-alpha):.0%})')

# Lignes critiques pointill√©es
plt.axvline(x=xcritic_left, color='black', linestyle='--',
            label=f'Borne critique = {xcritic_left:.2f}')
plt.axvline(x=xcritic_right, color='black', linestyle='--')

plt.title(f'Intervalle de confiance √† {(1-alpha):.0%}\n'
          f'(Œ± = {alpha}, Valeurs critiques = [{xcritic_left:.2f}, {xcritic_right:.2f}])',
          pad=20)
plt.xlabel('Valeurs standardis√©es')
plt.ylabel('Densit√© de probabilit√©')
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend()
plt.tight_layout()
plt.show()

"""Nous avons donc trac√© l'intervalle de confiance pour un alpha de 0.05, en prenant comme distribution le fait qu'avec le TCL :
$$ Z_n \longrightarrow \mathcal{N}(0,1)$$

Une fois l'IC trouv√© sur $Z_n$, reste √† revenir √† $\bar{X_n}$ en isolant $\mu$

$$ IC_{1-\alpha}(\mu) = \big[ \bar{X_n} - z_{1-\alpha/2}\frac{\sigma}{\sqrt n} ; \bar{X_n} + z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}} \big]
$$
Pour $\alpha = 0.05$,  la valeur critique $z_{1+\alpha/2} \approx 1.96$.

L'intervalle de confiance d√©pend alors que de $\alpha, n, \sigma$:
- plus $n$ augmente, plus l'intervalle se r√©duit autour de la valeur estim√©e.
- plus $\sigma$ est grand plus il est difficile d'avoir une estimation certaine car le processus sous-jacent est lui-m√™me incertain.
"""

# Param√®tres de la simulation
n = 30          # Taille de l'√©chantillon
alpha = 0.05    # Niveau de signification
T = 10000       # Nombre de r√©p√©titions
xcritic = abs(st.norm.ppf(alpha / 2))  # Valeur critique th√©orique (pour un test bilat√©ral)
compteur = 0    # Compteur d'intervals "corrects" (qui contiennent la vraie moyenne)

for _ in range(T):
    # G√©n√©ration d'un √©chantillon et calcul de sa moyenne
    echantillon = np.random.randn(n)
    moyenne_echantillon = echantillon.mean()
    # V√©rification si la moyenne est dans l'intervalle de confiance th√©orique
    if -xcritic/np.sqrt(n)< moyenne_echantillon < xcritic/np.sqrt(n):
        compteur += 1

# Calcul des r√©sultats
taux_empirique = (compteur / T) * 100      # % observ√©
taux_theorique = (1 - alpha) * 100         # % th√©orique attendu

# Affichage clair des r√©sultats
print("=== R√©sultats de la simulation ===")
print(f"‚Ä¢ Taille d'√©chantillon (n) : {n}")
print(f"‚Ä¢ Nombre de r√©p√©titions (T) : {T}")
print(f"‚Ä¢ Estimations de la moyenne √† partir d'un √©chantillon de n=30 valeurs : {moyenne_echantillon}")
print(f"‚Ä¢ Niveau de confiance th√©orique (1 - Œ±) : {taux_theorique:.2f}%")
print("-----------------------------------")
print(f"‚Ä¢ Taux empirique de r√©ussite : {taux_empirique:.2f}%")
print(f"‚Ä¢ √âcart th√©orique/empirique : {abs(taux_theorique - taux_empirique):.2f}%")
print("===================================")

"""Le r√©sultat de ce calcul est important car il permet de bien interpr√©ter le sens de l'intervalle de confiance.

## Mais la variance n'est pas connue !
- Comment proc√©der ? Quelle loi utiliser ?
- A partir d'un √©chantillon de $n=10$, calculer le nouvel intervalle de confiance.  

Lorsqu'on ne conna√Æt pas la variance d'une population, on ne peut pas utiliser la loi normale directement, car cette loi suppose que la variance est connue. C'est le cas souvent lorsqu'on s'int√©resse √† de petits √©chantillons. Pour ce faire, on utilise la loi de Student qui ne fais intervenir que l'√©cart type empirique de notre √©chantillon s.
L'intervalle de confiance peut s'√©crire ;

$$ IC_{1-\alpha} = \big[ \bar{X_n} - \left| F^{-1}_{T_{n-1}}(\frac{\alpha}{2}) \right|\frac{s}{\sqrt n} ; \bar{X_n} +  \left|F^{-1}_{T_{n-1}}(\frac{\alpha}{2}) \right|\frac{s}{\sqrt{n}} \big]
$$

Avec $F^{-1}_{T_{n-1}}(\frac{\alpha}{2}) $ la fonction inverse de la r√©partition de la distribution t de Student.
"""

# Param√®tres de la simulation
n = 5       # Taille de l'√©chantillon
alpha = 0.05    # Niveau de signification
T = 10000       # Nombre de r√©p√©titions
xcritic = abs(st.t.ppf(alpha / 2, n-1))  # Valeur critique th√©orique avec la loi de student
compteur = 0    # Compteur d'intervals "corrects" (qui contiennent la vraie moyenne)

for _ in range(T):
    # G√©n√©ration d'un √©chantillon et calcul de sa moyenne
    echantillon = np.random.randn(n)
    moyenne_echantillon = echantillon.mean()
    ecart = np.std(echantillon, ddof=1)

    # V√©rification si la moyenne est dans l'intervalle de confiance th√©orique
    if -xcritic/np.sqrt(n)*ecart < moyenne_echantillon < xcritic/np.sqrt(n)*ecart:
        compteur += 1

# Calcul des r√©sultats
taux_empirique = (compteur / T) * 100      # % observ√©
taux_theorique = (1 - alpha) * 100         # % th√©orique attendu

# Affichage clair des r√©sultats
print("=== R√©sultats de la simulation ===")
print(f"‚Ä¢ Taille d'√©chantillon (n) : {n}")
print(f"‚Ä¢ Nombre de r√©p√©titions (T) : {T}")
print(f"‚Ä¢ Estimations de la moyenne √† partir d'un √©chantillon de n=30 valeurs : {moyenne_echantillon}")
print(f"‚Ä¢ Niveau de confiance th√©orique (1 - Œ±) : {taux_theorique:.2f}%")
print("-----------------------------------")
print(f"‚Ä¢ Taux empirique de r√©ussite : {taux_empirique:.2f}%")
print(f"‚Ä¢ √âcart th√©orique/empirique : {abs(taux_theorique - taux_empirique):.2f}%")
print("===================================")

"""

# Analyse statistique de donn√©es
Cet exercice n√©cessite les fichiers de donn√©es suivant (√† t√©l√©charger sur moodle): `dataA.txt`.  


Dans son [article fondateur sur la r√©gression](http://www.stat.ucla.edu/~nchristo/statistics100C/history_regression.pdf), Francis Galton a √©tudi√© les tailles moyennes
de 205 couples ainsi que celles de leurs enfants. Nous nous int√©ressons ici aux tailles des parents seulement. Ces tailles, exprim√©es en pouces, sont fournies dans le fichier  `dataA.txt` (la premi√®re colonne correspond aux p√®res, la seconde aux m√®res).

"""

data = np.loadtxt("dataA.txt") # modifier le chemin si n√©cessaire

"""Explorons ces donn√©es.
- Afficher les histogrammes des tailles des p√®res et des m√®res.
- Afficher √©galement les histogrammes cumul√©s.
- Une autre mani√®re de visualiser les donn√©es est de regarder les "bo√Ætes √† moustaches" ou `boxplot`. Cette fonction existe dans matplotlib. Regarder la documentation et utiliser l√†. Comprendre les quantit√©s en pr√©sence.  
- Trouver les fonctions permettant de calculer les estimations de l‚Äôesp√©rance math√©matique, de la variance, et de l‚Äô√©cart-type de la distribution des tailles.
- Trouver aussi les estimateurs biais√©s de la variance et de l‚Äô√©cart-type.
- Trouver √©galement les fonctions fournissant les coefficients d‚Äôasym√©trie et d‚Äôaplatissement (idem, il en existe des versions biais√©es et non biais√©es). V√©rifier la coh√©rence de leurs valeurs avec les histogrammes.


"""

plt.figure(figsize=(15, 10))

tailles_peres= data[:, 0]
tailles_meres= data[:, 1]


plt.subplot(2, 3, 1)
plt.hist(tailles_peres, bins=30, color='skyblue', edgecolor='black')
plt.title('Distribution des tailles des p√®res')
plt.xlabel('Taille (cm)')
plt.ylabel('Fr√©quence')

plt.subplot(2, 3, 2)
plt.hist(tailles_meres, bins=30, color='salmon', edgecolor='black')
plt.title('Distribution des tailles des m√®res')
plt.xlabel('Taille (cm)')

# 2. Histogrammes cumul√©s
plt.subplot(2, 3, 4)
plt.hist(tailles_peres, bins=30, color='skyblue', edgecolor='black', cumulative=True, density=True)
plt.title('Distribution cumul√©e (p√®res)')
plt.xlabel('Taille (cm)')
plt.ylabel('Fr√©quence cumul√©e')

plt.subplot(2, 3, 5)
plt.hist(tailles_meres, bins=30, color='salmon', edgecolor='black', cumulative=True, density=True)
plt.title('Distribution cumul√©e (m√®res)')

plt.figure(3) #trac√© des moustaches
plt.boxplot([data[:, 0], data[:, 1]], labels=['P√®res', 'M√®res'],vert=False, patch_artist=True, boxprops=dict(facecolor='lightblue') )
plt.title('Bo√Ætes √† moustaches')
plt.xlabel('Taille (cm)')

plt.tight_layout()
plt.show()


def print_stats(name, data):
    print(f"\n--- Statistiques pour {name} ---")
    print(f"Moyenne (estimateur non biais√©): {np.mean(data):.2f} cm")
    print(f"Variance non biais√©e (n-1): {np.var(data, ddof=1):.2f}")
    print(f"Variance biais√©e (n): {np.var(data, ddof=0):.2f}")
    print(f"√âcart-type non biais√©: {np.std(data, ddof=1):.2f} cm")
    print(f"√âcart-type biais√©: {np.std(data, ddof=0):.2f} cm")
    print(f"Asym√©trie biais√© (skewness): {st.skew(data,bias=True):.2f}")
    print(f"Asym√©trie non biais√© (skewness): {st.skew(data,bias=False):.2f}")
    print(f"Aplatissement biais√© (kurtosis): {st.kurtosis(data,bias=True):.2f}")
    print(f"Aplatissement non biais√© (kurtosis): {st.kurtosis(data,bias=False):.2f}")
    print("===================================")

print_stats("les p√®res", tailles_peres)
print_stats("les m√®res", tailles_meres)

plt.figure(2) #Comparaison des 2 histogrammes
plt.hist(data.T[1], color = 'salmon', bins = 'rice', density=True, label= "m√®re",edgecolor='black')
plt.hist(data.T[0], color = 'skyblue', bins = 'rice', density=True, label = "p√®re",edgecolor='black')
plt.legend()
plt.title("Comparaison des 2 histogrammes")

"""On remarque qu'il n'y a pas de diff√©rence entre les coefficients d'aplatissement et d'asym√©trie biais√©s et non biais√©s.

Pour les m√®res, les deux coefficients d'asym√©trie sont tr√®s proches de z√©ro (+0,012). Cela indique que les distributions sont quasiment sym√©triques. Une asym√©trie aussi faible signifie qu‚Äôil n‚Äôy a pas de queue dominante, ni √† gauche ni √† droite. Les coefficients d'aplatissement sont n√©gatifs (‚Äì0,18). Cela signifie que les distributions sont moins pointues qu‚Äôune loi normale, avec des queues plus fines (moins de valeurs extr√™mes).

# Test de conformit√©

Le  test nomm√© *chi-square goodness-of-fit test* d√©termine si un √©chantillon de donn√©es peut √™tre consid√©r√© comme issu d'une distribution de probabilit√© dont les param√®tres pourraient √™tre estim√©s √† partir des observations.  Le test regroupe les donn√©es selon des groupes et calcul les comptes observ√©s et attendus (selon la distribution hypoth√®se). Ici on part de l'histogramme, les groupes peuvent se d√©duire donc de l'histogramme surtout si on a d√©fini nous-m√™me les intervalles. Puis les effectifs sont compar√©s gr√¢ce √† la loi du $\chi^2$:

$$\chi^2=\sum_{i=1}^{N} \frac{(O_i‚àíE_i)^2}{E_i}‚Äâ,$$

avec $O_i$ les comptes observ√©s et $E_i$ les comptes attendus. La statistique de test suit alors une loi du $\chi^2$ quand les comptes sont suffisants. Notons que la convergence de la distribution du $\chi^2$ est asymptotique mais, en pratique, l‚Äôapproximation est correcte si $E_i \geq 5\ \ \forall i$.


Pour tester la conformit√© des donn√©es (les deux colonnes) vis-√†-vis d'une distribution gaussienne:

- On peut appliquer √† l'histogramme un test du $\chi^2$. Quelles sont les grandeurs que l'on veut comparer ? Comment les calculer ? Repr√©senter ces grandeurs graphiquement. On souhaite comparer les donn√©es empiriques des tailles des personnes avec une gausienne th√©oriques. On d√©termine la forme de la gausienne th√©orique √† l'aide de la moyenne et de l'√©cart-type.
- Tester le caract√®re gaussien des deux distributions √† l‚Äôaide du test de $\chi^2$ de conformit√© √† une distribution. Il faut faire attention √† comment on choisit les intervalles !

Th√©oriquement, on peut d√©terminer les quantiles th√®oriques d'une loi normal. La $i^{√®me}$ valeur correspond en moyenne au quantile $p_i = \frac{i-0.5}{n}$ de la loi. On peut alors d√©terminer le quantile normale par la fonction quantile $z_i = \phi^{-1}(p_i)$

- Tracer et interpr√©ter les diagrammes quantile-quantile des distributions.
- Calculer la droite de Henri.
Th√©otiquement la droite de Henri pour une loi normal √† une √©quation $ y = \mu + z \times \sigma$
"""

#Pour les tailles des p√®res
tailles_peres= data[:, 0]
n = len(tailles_peres)


moyenne = np.mean(tailles_peres)
ecart = np.std(tailles_peres)
V = np.std(tailles_peres)
M = 15 # pour contr√¥ler le nombre de bins dans la distribution
X = 0

plt.figure(1) # On repr√©sente l'histogramme des
h2, bins, p  = plt.hist(tailles_peres,bins = M , density=False, color='skyblue', edgecolor='black') # On repr√©sente l'histogramme des tailles des p√®res


E = st.norm.cdf(bins[1:], loc=moyenne, scale=ecart) - st.norm.cdf(bins[:-1], loc=moyenne, scale=ecart) # On d√©termine les E(i) attendus √† partir de la moyenne et de l'ecart type. On soustrait les fonctions de r√©partition en d√©cal√© pour avoir acc√®s √† l'aire sous la courbe.

plt.figure(2)
plt.plot(E*n, color = 'r', label = 'attendus')
plt.hist(tailles_peres-63,bins = M , density=False, color='skyblue', edgecolor='black')
plt.plot(h2,color = 'b', label = 'observ√©s')
plt.legend()
plt.title("Comparaison des courbes de distributions observ√©es et attendus")

X = (h2-E*n)**2/(E*n)


print(f"La valeur de Z pour les p√®res est :",  np.sum(X) )
print('======================================')


Taille = np.sort(tailles_peres)  # On trie les tailles des p√®res
prob_theoriques = (np.arange(1, n+1) - 0.5) / n # Calcul des probabilit√©s th√©oriques

z_theoriques = st.norm.ppf(prob_theoriques) # Valeurs normales th√©oriques (quantiles)


# Trac√© de la droite de Henry
plt.figure()
plt.plot(z_theoriques, Taille, 'o', label = "Quantile- Quantile")
plt.plot(z_theoriques, moyenne + ecart*z_theoriques, label = "droite d'Henri")
plt.legend()
plt.title("Droite de Henry")
plt.xlabel("Quantiles th√©oriques (normale)")
plt.ylabel("Quantiles empiriques (Donn√©es tri√©es)")
plt.grid(True)
plt.show()

#Pour les tailles des m√®res
tailles_meres= data[:, 1]
n = len(tailles_meres)


moyenne = np.mean(tailles_meres)
ecart = np.std(tailles_meres)
V = np.std(tailles_meres)
M = 15 # pour contr√¥ler le nombre de bins dans la distribution
X = 0

plt.figure(1) # On repr√©sente l'histogramme des tailles des femmes
h1, bins, p  = plt.hist(tailles_meres,bins = M , density=False, color='salmon',edgecolor='black') # On repr√©sente l'histogramme des tailles des p√®res


E = st.norm.cdf(bins[1:], loc=moyenne, scale=ecart) - st.norm.cdf(bins[:-1], loc=moyenne, scale=ecart) # On d√©termine les E(i) attendus √† partir de la moyenne et de l'ecart type. On soustrait les fonctions de r√©partition en d√©cal√© pour avoir acc√®s √† l'aire sous la courbe.

plt.figure(2)
plt.plot(E*n, color = 'b', label = 'attendus')
plt.plot(h1,color = 'r', label = 'observ√©s')
plt.hist(tailles_meres-57.5,bins = M , density=False, color='salmon',edgecolor='black')
plt.legend()
plt.title("Comparaison des courbes de distributions observ√©es et attendus")

X = (h1-E*n)**2/(E*n)


print(f"La valeur de Z pour les m√®res  est :",  np.sum(X) )
print('======================================')



Taille = np.sort(tailles_meres)  # On trie les tailles des p√®res
prob_theoriques = (np.arange(1, n+1) - 0.5) / n # Calcul des probabilit√©s th√©oriques

z_theoriques = st.norm.ppf(prob_theoriques) # Valeurs normales th√©oriques (quantiles)


# Trac√© de la droite de Henry
plt.figure()
plt.plot(z_theoriques, Taille, 'o',color= 'salmon', label = "Quantile- Quantile")
plt.plot(z_theoriques, moyenne + ecart*z_theoriques, label = "droite d'Henri")
plt.legend()
plt.title("Droite de Henry")
plt.xlabel("Quantiles th√©oriques (normale)")
plt.ylabel("Quantiles empiriques (Donn√©es tri√©es)")
plt.grid(True)
plt.show()

"""Pour les p√®res, on obtient des r√©sultats empiriques qui sont bien align√©s sur la droite de Henry, ce qui signifie que les donn√©es suivent bien la distribution de la loi normale.
Pour les m√®res, les r√©sultats empiriques sont moins bien align√©s sur la droite de Henry, ce qui signifie que les donn√©es ne suivent pas parfaitement la distribution de la loi normale.
Par ailleurs, on observe que le Z pour les p√®res (14) est plus petit que le Z pour les m√®res (43), ce qui t√©moigne du fait que les valeurs pour les p√®res suivent davantage une loi normale. En effet, cela signifie que l'intervalle de confiance des valeurs est plus important.

Nous avons d√©termin√© que l'un des deux (ou les deux ?) √©chantillons provenaient d'une distribution gaussienne. Commen√ßons par calculer les intervalles de confiance des deux moyennes pour comparer ces deux estimateurs. Puis, en utilisant le test de student pour d√©terminer si les moyennes des distributions sont diff√©rentes, ou pas:
- Construire les intervalles de confiance des deux moyennes (avec degr√©s de confiance 0.95).
- Pr√©alablement au test de student, d√©terminer si les variances des deux distributions sont √©gales.
- Effectuer le test de student ou welch avec : $$H_0: \mu_1 = \mu_2$$.
"""

#On d√©termine les intervalles de confiance pour les p√®res

moyennep = np.mean(tailles_peres)
ecartp = np.std(tailles_peres)
Vp = np.std(tailles_peres)
z = st.norm.ppf(1 - alpha/2)
IC1 = (moyennep - z * ecartp /np.sqrt(n), moyennep + z *ecartp /np.sqrt(n))

#On d√©termine les intervalles de confiance pour les m√®res
moyennem = np.mean(tailles_meres)
ecartm = np.std(tailles_meres)
Vm = np.std(tailles_meres)
z = st.norm.ppf(1 - alpha/2)
IC2 = (moyennem - z * ecartm /np.sqrt(n), moyennem + z *ecartm /np.sqrt(n))

print("IC 95% moyenne p√®res :", IC1)
print("IC 95% moyenne m√®res :", IC2)

import matplotlib.pyplot as plt
import numpy as np

# Moyennes et intervalles de confiance √† 95 %
labels = ['P√®res', 'M√®res']
moyennes = [moyennep, moyennem]
basses = [IC1[0], IC2[0]]
hautes = [IC1[1], IC2[1]]
erreurs_inf = [moyennep - IC1[0], moyennem - IC2[0]]
erreurs_sup = [IC1[1] - moyennep, IC2[1] - moyennem]


x = [0.9, 1.1]

fig, ax = plt.subplots(figsize=(8, 6))

# Trac√© avec barres d'erreur
ax.errorbar(
    x, moyennes, yerr=[erreurs_inf, erreurs_sup],
    fmt='o', capsize=8, color='navy', ecolor='skyblue',
    label="Intervalle de confiance √† 95 %"
)

ax.set_title("Taille moyenne avec intervalle de confiance √† 95 %", fontsize=14)
ax.set_ylabel("Taille moyenne (cm)", fontsize=12)
ax.set_ylim(min(basses) - 2, max(hautes) + 2)
ax.set_xlim(0.5, 1.5)
ax.set_xticks(x)
ax.set_xticklabels(labels)
ax.grid(True, linestyle='--', alpha=0.6)


ax.legend(loc='upper right')
for i, moyenne in enumerate(moyennes):
    ax.annotate(f"{moyenne:.2f} cm", (x[i], moyennes[i] + 0.5), ha='center', fontsize=10)


plt.tight_layout()
plt.show()

"""Nous souhaitons savoir si les variances des deux listes sont √©gales. On √©met alors l'hypoth√®se $H_0 : \sigma_1^2 = \sigma_1^2$.

Nous construisons la variable al√©atoire de Fisher-Snedecor.
Cette variable al√©atoire (si $H_0$ est vrai) v√©rifie  :
$F = \frac{S1 \sigma_2^2}{S2 \sigma_1^2} ‚âà F_{n_1-1, n_2-1}$

$H_0$ est vrai si : $f_{\alpha /2}(n_1-1,n_2-1) < f = (\frac{s_1}{s_2})^2 < f_{1- \alpha /2}(n_1-1,n_2-1)$
"""

n = len(tailles_peres)
f = ecartp**2/ecartm**2
f1 = st.t.ppf(alpha/2, 2*n -2)
f2 = st.t.ppf(1-alpha/2, 2*n -2)

print(f"Statistique f calcul√©e : {f:.4f}")
print(f"Intervalle de confiance pour F au seuil de 5 % : [{f1:.4f} ; {f2:.4f}]")

if f1 < f < f2:
    print("‚Üí La statistique F est dans l'intervalle de confiance : on accepte l'hypoth√®se H0.")
    print("‚Üí Conclusion : les variances des deux √©chantillons peuvent √™tre consid√©r√©es comme √©gales au seuil de 5 %.")

"""On peut conclure que les variances des deux listes sont √©gales avec un risque de 5 %.

- Pour effectuer un Test de Welch, il faut calculer la statistique $$ T = \frac{\bar{Y_1} - \bar{Y_2}}{S \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}} ‚âà ùö™_{n_2 + n_1 -2}$$
Si l'hypoth√®se $H_0$ est v√©rifi√©e, alors $t < t_{\alpha /2}(n_1 +n_1 -2)$
"""

t = (moyennem -moyennep)/(ecartp*np.sqrt(2/n))
tf = st.t.ppf(alpha/2, 2*n -2)
print(f"Valeur de t : {t}")
print(f"Intervalle de confiance √† 95 % : [{tf}, {-tf}]")

if tf < t < -tf:
    print("‚úÖ La statistique t appartient √† l'intervalle de confiance : on **accepte** l'hypoth√®se nulle H‚ÇÄ.")
else:
    print("‚ùå La statistique t est en dehors de l'intervalle de confiance : on rejette l'hypoth√®se nulle H‚ÇÄ.")

"""L'hypoth√®se $H_0$ n'est pas v√©rifi√©e ce qui implique que les deux moyennes sont diff√©rentes avec un risque de moins de 5%.

# Hypercholest√©rol√©mie primaire en monoth√©rapie
Une √©tude randomis√©e en double aveugle contre placebo a √©t√© men√©e sur 827 patients trait√©s √† l‚Äôhypocholest√©rol√©miant, et 892 patients auxquels a √©t√© administr√© un placebo. Pour chaque patient, on a mesur√© la variation du taux de cholest√©rol LDL (Low Density Lipoprotein, ou mauvais cholest√©rol) entre le d√©but et la fin du
traitement. Les r√©sultats sont les suivants :

|   | traitement | placebo |
|---|------------|---------|
| effectifs F | 428   | 502  |
| effectifs H | 399  | 390  |
|   25-44 ans |  162    |  210 |
| 45-64 ans  | 403|423 |
| sup 65 ans  | 262 | 259 |
| $\sum$ des variations | ‚Äì 528.4477 | -116.0837 |
| $\sum$ des √©carts | 76.1925 | 35.8899 |


Pour la somme des variations et des √©carts:
$$ \sum_k \delta_k \text{ en g/l et } \sum_k (\delta_k-\bar{\delta})^2$$


## Cohorte
Pr√©alablement √† l‚Äô√©tude statistique proprement dite, on souhaite s‚Äôassurer que les deux √©chantillons sont √©quilibr√©s entre eux, √† la fois en √¢ge et en sexe. Effectuer les tests ad√©quats. Pour tous les tests, que l‚Äôon effectuera avec un risque d‚Äôerreur de premi√®re esp√®ce Œ± = 5%, on explicitera les hypoth√®ses non remises en question, l‚Äôhypoth√®se nulle et l‚Äôhypoth√®se alternative.


Puis calculer les estimations ponctuelles de l‚Äôesp√©rance math√©matique (e.m.), de la variance et de l‚Äô√©cart-type de la variation du taux de cholest√©rol LDL dans les deux groupes.

Afin de d√©terminer si les deux √©chantillons sont √©quilibr√©s entre eux en sexe, nous r√©alisons le test $H_0 : \mu_1 = \mu_2$ pour des grands echantillons. nous posons :  
$$ Z = \frac{\bar{Y_1} - \bar{Y_2}}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}} ‚âà N(0,1)$$
Si l'hypoth√®se $H_0$ est v√©rifi√©e, alors $z < z_{\alpha /2}$.


Nous r√©alisons le test d'√©galit√© des probabilit√©s pour les hommes. Les lois pour les sexes suivent une loi binomial de param√®tres $p_t = \frac{399}{827} = 48,25 \%$, $n_t = 827$ et $p_p = 43,72 \% $, $n_p = 892$. Les √©chantillons √©tant de grande taille on peut approximer les lois binomiales par des gausiennes.
"""

alpha = 0.05
traitement = [428, 399, 162, 403, 262, -528.4477, 76.1925]
placebo = [502, 390, 210, 423, 259, -116.0837, 35.8899]
alpha = 0.05
N_traitement = traitement[0] + traitement[1]
N_placebo = placebo[0] + placebo[1]



#On verifie l'homog√©n√©it√© pour le sexe
table_sexe = np.array([[traitement[0], placebo[0]],
                       [traitement[1], placebo[1]]])

n_t = table_sexe[0][0]+table_sexe[1][0]
n_p = table_sexe[1][1]+table_sexe[0][1]
p_t = table_sexe[1][0]/(n_t)
p_p = table_sexe[1][1]/(n_p)


ecart_t = np.sqrt((1-p_t)*p_t*n_t)
ecart_p = np.sqrt((1-p_p)*p_p*n_p)

z = (p_t - p_p)/np.sqrt(ecart_t**2/n_t**2 + ecart_p**2/n_p**2)
z_test = st.norm.ppf(alpha/2)


# Affichage des r√©sultats du test d'homog√©n√©it√© pour le sexe
print("=== Test d'homog√©n√©it√© des proportions hommes/femmes ===")
print(f"Taille √©chantillon traitement: {n_t} patients")
print(f"Taille √©chantillon placebo: {n_p} patients")
print(f"Proportion d'hommes dans le groupe traitement: {p_t*100:.2f}%")
print(f"Proportion d'hommes dans le groupe placebo: {p_p*100:.2f}%")
print("\n=== R√©sultats du test statistique ===")
print(f"Score z calcul√©: {z:.4f}")
print(f"Valeur critique pour alpha={alpha}: ¬±{abs(z_test):.4f}")
print("\n=== Conclusion ===")
if abs(z) < abs(z_test):
    print(f"Comme |{z:.4f}| < {abs(z_test):.4f}, nous ne rejetons pas H0.")
    print("Les deux √©chantillons sont homog√®nes concernant la r√©partition hommes/femmes avec un risque < √† 5%")

"""Nous pouvons ainsi affirmer que les deux √©chantillons sont homog√®nes avec un risque moins de 5 %.


Pour v√©rifier l'homog√©n√©it√© suivant l'√¢ge, nous r√©alisons un test du chi carr√©.

$$D^2 =\sum{j=1}_a \sum_{i=1}^b \frac{(N_{ij}-\bar{N_{ij}})^2}{\bar{N_{ij}}}$$

Nous obtenons le tableau de continguence suivant :

|   | 25-44 ans | 45-64 ans |sup 65 ans|Total |
|----------|------------|---------| --------| |
| Traitement |  162 | 403  | 262  | 827|
| Placebo | 210 | 423 | 259  |892 |
|   Total |  372  |  826 | 521 | 1719
"""

#On verifie l'homog√©n√©it√© pour l'√¢ge
table_age = np.array([[traitement[2], placebo[2]],
                      [traitement[3], placebo[3]],
                      [traitement[4], placebo[4]]])
n = table_age[0][0]+table_age[0][1]+ table_age[1][0]+ table_age[1][1] +table_age[2][0] + table_age[2][1]

n11 = table_age[0][0]+table_age[0][1]
n12 = table_age[1][0]+table_age[1][1]
n13 = table_age[2][0]+table_age[2][1]

n21 = table_age[0][0]+table_age[1][0]+ table_age[2][0]
n22 = table_age[0][1]+table_age[1][1]+ table_age[2][1]

N12 = n11 * n22/n
N11 = n11 * n21/n
N21 = n12 * n21/n
N22 = n12 * n22/n
N31 = n13 * n21/n
N32 = n13 * n22/n
d2 = (table_age[0][0]-N11)**2/N11 + (table_age[0][1]-N12)**2/N12 + (table_age[2][0]-N31)**2/N31 + (table_age[1][0]-N21)**2/N21 + (table_age[1][1]-N22)**2/N22 + (table_age[2][1]-N32)**2/N32

C = st.chi2.ppf(1-alpha,2)

print("\n=== Test du Chi-deux sur la r√©partition par √¢ge ===")
print(f"\nStatistique du test : D¬≤ = {d2:.3f}")
print(f"Seuil critique (Œ±={alpha}) : {C:.3f}")

if d2 < C:
    print("\nConclusion : Les distributions d'√¢ge sont homog√®nes (p > 0.05)")
    print(f"‚Üí On accepte H0 (D¬≤ = {d2:.3f} < {C:.3f})")

"""L'homog√©n√©it√© selon l'√¢ge est bien v√©rifi√©e gr√¢ce au test du Chi-Deux"""

# D√©termination des moyennes, √©cart-types et variances

moyenne_traitement = traitement[5]/N_traitement
ecart_traitement = traitement[6]/(N_traitement-1)
V_traitement = np.sqrt(ecart_traitement)
moyenne_placebo = placebo[5]/N_placebo
ecart_placebo = placebo[6]/(N_placebo-1)
V_placebo = np.sqrt(ecart_placebo)

print("===================================")
print(f"Moyenne traitement: {moyenne_traitement} g/L")
print(f"Ecart traitement: {ecart_traitement} ")
print(f"Variance traitemnt: {V_traitement} ")
print(f"Moyenne placebo: {moyenne_placebo} g/L")
print(f"Ecart placebo: {ecart_placebo} ")
print(f"Variance placebo: {V_placebo} ")
print("===================================")

"""## Efficacit√©

 D√©terminer, en conduisant le(s) test(s) ad√©quat(s), si  l‚Äôhypocholest√©rol√©miant est plus efficace que le placebo  pour ce type de patients. Donner des estimations ponctuelle et par intervalle (au  seuil de confiance 5%) de l‚Äô√©cart entre la diminution  obtenue avec le traitement et celle obtenue avec le  placebo.

Afin de d√©terminer, le moyen le plus efficace, on r√©alise un test de comparaison. Les effectifs sont tr√®s grands, Nous n'avons pas besoin de faire le test d'√©galit√© des variance. Nous √©m√©ttons l'hypoth√®se $H_0 = \nu_t = \nu_p$

$$ Z = \frac{\bar{Y_t} - \bar{Y_p}}{\sqrt{\frac{s_t^2}{n_t} + \frac{s_p^2}{n_p}}} ‚âà N(0,1)$$

Si l'hypoth√®se $H_0$ est v√©rifi√©e, alors $z < z_{\alpha /2}$.

On d√©termine le $\chi^2$, on r√©alise le teste de Student ou de Welsh et on compare au $\alpha$. Dans notre cas de figure, il y a une seule donn√©es par groupe (n=1). La fonction chi2_contingency() permet de r√©aliser tous nos calculs pr√©c√©dent directement.



Ainsi, on a deux banques de donn√©es qui sont √©quilibr√©es selon l'√¢ge et le sexe. La r√©partition selon le sexe et l'√¢ge est la m√™me dans les deux groupes.
Autrement dit, sexe et groupe, et √¢ge et groupe, sont ind√©pendants. L'hypoth√®se nulle est v√©rifi√©e.
"""

z = (moyenne_traitement - moyenne_placebo)/np.sqrt(ecart_traitement/N_traitement +ecart_placebo/N_placebo)

z_test= st.norm.ppf(alpha/2)

print("=== R√©sultats du test Z ===")
print(f"Statistique Z = {z:.4f}")
print(f"Seuil critique (Œ±=5%) = ¬±{abs(z_test):.4f}")
print("\n=== Conclusion ===")
print(f"R√©sultat du test : z = {z:.4f} < z_critique = {z_test:.4f}")
print("‚Üí On rejette H0 : le traitement est significativement plus efficace que le placebo avec un risque de 5%")

"""Nous en d√©duisons que le traitement est plus efficace que le placebo avec un risque de 5% de se tromper.

Pour d√©terminer des estimations ponctuelle et par intervalle (au  seuil de confiance 5%) de l‚Äô√©cart entre la diminution  obtenue avec le traitement et celle obtenue avec le  placebo, nous posons :

$$ \bar{Y} = \frac{\bar{Y_t} - \bar{Y_p} - (\mu_t-\mu_p)}{\sqrt{\frac{s_t^2}{n_t} + \frac{s_p^2}{n_p}}} ‚âà N(0,1)$$
"""

# Calcul de l'intervalle de confiance
diff = moyenne_traitement - moyenne_placebo
std_error = np.sqrt((ecart_traitement**2)/N_traitement + (ecart_placebo**2)/N_placebo)
z_critique = st.norm.ppf(1 - alpha/2)  # Valeur critique bilat√©rale

IC_inf = diff - z_critique * std_error
IC_sup = diff + z_critique * std_error

print("\n=== Estimation de l'effet traitement ===")
print(f"Diff√©rence moyenne (Traitement - Placebo) : {diff:.2f}")
print(f"Erreur standard de la diff√©rence : {std_error:.4f}")
print("\nIntervalle de confiance √† 95% :")
print(f"[{IC_inf:.2f} ; {IC_sup:.2f}]")
print("\nInterpr√©tation :")
print("Avec 95% de confiance, la vraie diff√©rence d'efficacit√© entre le traitement")
print(f"et le placebo se situe entre {IC_inf:.2f} et {IC_sup:.2f} unit√©s.")



"""En regardant les intervalles de confiances, on peut dire que la m√©thode de traitement est plus efficace que celle du placebo."""